# Scan

## Scan two processor (shared memory)implementation

**双处理器（共享内存）扫描实现**
性能分析
计算复杂度：工作复杂度为
O(N)
 ，但常数因子降低到 1.5 ，相比一些简单实现有所优化。
数据访问特性：具有高空间局部性，因为是连续内存访问。不过在大核心数且内存访问成本非均匀的系统中，
P1访问 a8到a11可能成本较高，但在小规模多核系统中，与P2的访问成本可能相同。

## CUDA 中独占扫描的 SIMD 实现

**代码功能**

以 32 元素数组的独占扫描为例，在 32 路 GPU 执行（单程序多数据，SPMD）模式下 。scan_warp 函数是设备端函数（device修饰 ）。
首先通过 idx % 32 计算线程束（warp）内线程索引 lane （范围 0 - 31 ）。然后通过一系列 if 语句，根据 lane 的值，将当前元素与之前特定间隔的元素相加，逐步实现扫描操作 。最后根据 lane 是否大于 0 ，返回前一个元素的值或者 0 。

**性能分析**

计算复杂度：工作复杂度为 Nlg(N)
效率分析：在当前上下文中，工作高效的扫描公式并不能带来好处，因为会导致 SIMD 利用率低。一个工作高效的算法相比当前实现需要超过两倍的指令数。

## builing scan on larger array并行扫描算法的基础实现

**双处理器（共享内存）扫描实现**

这样做计算复杂度是
O(N)
 ，常数还挺小，而且内存访问连续，空间局部性好，但在大核心数系统里访问可能有点麻烦 。

 **CUDA 中独占扫描的 SIMD 实现**

CUDA 中独占扫描的 SIMD 实现：以 32 元素数组为例，在 GPU 里用线程束（warp ，32 个线程一组 ）干活。每个线程先算自己在 warp 里的索引，然后根据索引把当前元素和前面特定间隔的元素相加，一步步实现扫描，最后根据索引决定返回啥。这计算复杂度是
Nlg(N) ，但在当前情况下 SIMD 利用率高 。

构建更大规模数组的扫描
128 元素数组扫描：用四个线程束（warp ）组成线程块来处理 128 元素数组。每个 warp 先做 32 元素的 SIMD 扫描，然后再汇总处理，最后并行更新。就是先把数组分成几块分别扫描，再把结果整合起来 。
多线程 SIMD CUDA 实现：CUDA 线程块里的线程合作做扫描。先是每个 warp 做部分扫描，然后每个 warp 里的 31 号线程把部分结果存起来，接着 0 号 warp 再做一次扫描汇总，最后其他 warp 根据前面的结果更新自己的值 。
百万元素数组扫描：百万元素的数组，每个线程块处理 1024 个元素。分几步，先每个块里做 SIMD 扫描，再汇总，最后并行更新。超过百万元素就得把数组再分块并行处理 。

**扫描算法设计要点**

并行性：扫描算法能并行干活，复杂度
O(N)，但高效实现得合理用并行，目标是减少计算量和通信、同步开销 。
局部性：得匹配内存层次，像 CUDA 里就在局部内存里做每个块的扫描 。
算法异构性：不同层面扫描策略不同，比CUDA 里线程束内和线程间扫描算法不一样，低核心数 CPU 就多用顺序扫描 。

**分段扫描**

常见问题：处理序列的序列，像图里顶点和边、模拟里粒子、文档里单词这些，有两级并行性，但不同部分规模差异大 。
原理：对输入序列的连续分区同时做扫描。比如输入数组 A ，用 “开始标志” 表示嵌套序列，按规则算出结果。有个具体算法分向上扫描（Up - sweep ）和向下扫描（Down -sweep ）两步，通过循环和判断语句，根据标志位处理数据 。

**Gather和Scatter操作**

Gather 操作
定义：根据索引序列（index_seq）从数据序列（data_seq）中收集数据，存入输出序列（output_seq） 。简单理解，就像从一堆物品里，按照特定顺序挑出东西放在新的地方。
示例：幻灯片中给出 output_seq = gather(index_seq, data_seq) 。比如有数据序列 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]，索引序列 [3, 12, 4, 9, 9, 15, 13, 0] ，就从数据序列里按索引挑出对应元素组成输出序列。
数学表达：output[i] = input[index[i]] ，即输出序列的第 i 个元素，是输入序列中索引为 index[i] 的元素。

**Scatter 操作**

定义：根据索引序列（index_seq），把数据序列（data_seq）里的数据分散到输出序列（output_seq）对应的位置。可以想象成把东西按特定位置摆放。
示例：幻灯片中 output_seq = scatter(index_seq, data_seq) 。例如数据序列和索引序列确定后，将数据按索引放入输出序列相应位置。
数学表达：output[index[i]] = input[i] ，也就是输入序列第 i 个元素，放到输出序列索引为 index[i] 的位置。

**稀疏矩阵Sparsematrimultiplication**

-矩阵特点

矩阵中大部分值为 0 ，比如幻灯片中的矩阵示例，很多元素都是 0 。这样的矩阵如果按常规方式存储和计算会浪费空间和时间。

-并行计算

不同行的点积运算可以并行进行，能提高计算效率。但每行计算量不同，这给单指令多数据（SIMD）执行带来麻烦。

-存储格式

以压缩稀疏行（compressed sparse row）格式为例。用三个数组表示矩阵：
values：存储矩阵非零元素，如 values = [[3,1], [2], [4], ..., [2,6,8]] 。
cols：记录非零元素所在列索引，像 cols = [[0,2], [1], [2], [1,2,3]] 。
row_starts：指示每行非零元素在 values 数组中的起始位置，例如 row_starts = [0, 2, 3, 4, ...] 。

-计算步骤

（以带 scan 的稀疏矩阵乘法为例）
步骤一：对所有非零值进行映射。将 values 数组里每个非零值与 x 向量对应列索引元素相乘，比如 products[i]=values[i] * x[cols[i]] ，得到 products = [3x₀, x₂, 2x₁, 4x₂, 2x₁, 6x₂, 8x₃] ，这里用了 gather 操作从 x 向量收集数据。
步骤二：根据 row_starts 创建标志向量，如 flags = [1,0,1,1,1,0,0] 。
步骤三：对 (products, flags) 执行包含性分段扫描（inclusive segmented - scan） ，用加法操作得到 [3x₀, 3x₀+x₂, 2x₁, 4x₂, 2x₁, 2x₁+6x₂, 2x₁+6x₂+8x₃] 。
步骤四：取每个段的最后一个元素，得到结果向量 y = [3x₀+x₂, 2x₁, 4x₂, 2x₁+6x₂+8x₃] 。
Scan 和 Segmented scan
Scan 操作
理论：从理论上讲，问题的并行性与元素数量呈线性关系。即元素越多，并行潜力越大。
实践：实际应用中，要利用局部性原理，按需使用并行性来充分利用机器执行资源，不是盲目追求高并行度。这也是在机器不同层级应用不同策略的典型例子。
Segmented scan 操作
用于对不规则数据结构（如列表的列表）进行规则的数据并行计算。把复杂不规则结构展平处理，当成大型数据并行计算任务，方便高效运算。
